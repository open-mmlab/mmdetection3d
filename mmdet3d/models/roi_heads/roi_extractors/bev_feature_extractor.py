# Copyright (c) OpenMMLab. All rights reserved.
import torch
from mmcv.runner import BaseModule
from torch.nn import functional as F

from mmdet3d.core.bbox import (CameraInstance3DBoxes, DepthInstance3DBoxes,
                               LiDARInstance3DBoxes)
from mmdet.models.builder import ROI_EXTRACTORS


@ROI_EXTRACTORS.register_module()
class BEVFeatureExtractor(BaseModule):
    """Extract features from the BEV featrue map generated by the one-stage
    backbone.

    Args:
        pc_start (list[float]): Start point of point cloud's range
        voxel_size (list[float]): Voxel size of first 2 dimensions
        downsample_stride (int): Downsample factor of the backbone feature map
    """

    def __init__(
        self,
        pc_start,
        voxel_size,
        downsample_stride,
    ):
        super(BEVFeatureExtractor, self).__init__()
        self.pc_start = pc_start
        self.voxel_size = voxel_size
        self.downsample_stride = downsample_stride

    def forward(self, bev_feature, rois):
        """Forward function to BEV feature extractor.

        Args:
            bev_feature (list[torch.Tensor]): Multi-level feature maps. The
                 shape of each feature map is [B, C_i, H_i, W_i]
            rois (list[list[bboxes, ...]]): Decoded bbox, scores and labels
                The out list indicates the rois in a batch.

                - bboxes (:obj:`BaseInstance3DBoxes`): Prediction bboxes

        Returns:
            list[torch.Tensor]: roi features with shape of [N, 5*C]
        """

        # NOTE: ONLY surpport the latest output of BEV feature maps now
        bev_feature = bev_feature[-1]

        roi_features = []
        batch_size = len(bev_feature)
        num_points = 5
        for i in range(batch_size):
            bboxes = rois[i][0]
            num_boxes = len(bboxes)
            feature_points = self.get_feature_points(bboxes)  # [5*num_box, 2]

            xs = (feature_points[..., 0] - self.pc_start[0]
                  ) / self.voxel_size[0] / self.downsample_stride
            ys = (feature_points[..., 1] - self.pc_start[1]
                  ) / self.voxel_size[1] / self.downsample_stride

            features = self.bilinear_interpolate(bev_feature[i], xs,
                                                 ys)  # [5*num_box, C]

            roi_feature = torch.cat([
                features[i * num_boxes:(i + 1) * num_boxes]
                for i in range(num_points)
            ],
                                    dim=1)  # [num_box, 5*C]
            roi_features.append(roi_feature)
        return roi_features

    @staticmethod
    def get_feature_points(bbox):
        """Get feature points of bbox.

        Args:
            bbox (:obj:`BaseInstance3DBoxes`): Prediction bboxes

        Returns:
            torch.Tensor: The location of feature points. [5*num_box, 3]
        """

        # get corners
        if isinstance(bbox, LiDARInstance3DBoxes):
            front_left = bbox.corners[:, 4, :2].squeeze(1)  # [num_box, 2]
            back_left = bbox.corners[:, 0, :2].squeeze(1)
            front_right = bbox.corners[:, 7, :2].squeeze(1)
            back_right = bbox.corners[:, 3, :2].squeeze(1)
        elif isinstance(bbox, CameraInstance3DBoxes):
            raise NotImplementedError
        elif isinstance(bbox, DepthInstance3DBoxes):
            raise NotImplementedError
        else:
            raise NotImplementedError

        # get feature points
        center = bbox.bottom_center[:, :2]  # [num_box, 2]
        front = (front_left + front_right) / 2.0
        back = (back_left + back_right) / 2.0
        left = (front_left + back_left) / 2.0
        right = (front_right + back_right) / 2.0
        points = torch.cat([center, front, back, left, right],
                           dim=0)  # [5*num_box, 2]
        return points

    @staticmethod
    def bilinear_interpolate(bev_feats, x, y):
        """Sample features in bev by bilinear interpolation.

        Args:
            bev_feature (torch.Tensor): Features in BEV with shape of
                [C, H, W].
            x (torch.Tensor): The location of points with shape of [N]
            y (torch.Tensor): The location of points with shape of [N]

        Returns:
            torch.Tensor: Sampled features with shape of [N, C]
        """
        C, H, W = bev_feats.shape[-3:]
        x_norm = x / (W - 1) * 2 - 1
        y_norm = y / (H - 1) * 2 - 1
        grid = torch.cat([x_norm.view(-1, 1), y_norm.view(-1, 1)], dim=1)
        grid = grid.unsqueeze(0).unsqueeze(0)

        bev_feats = bev_feats.unsqueeze(0)

        feat = F.grid_sample(
            bev_feats, grid, mode='bilinear', align_corners=True)

        feat = feat.view(C, -1).permute(1, 0)
        return feat
